---
title: "Homework of  SC19051"
author: "19051"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to SC19051}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---


# HW1

## Assignment
Exercises 3.4, 3.11, and 3.18 (pages 94-96, Statistical Computating with R).

---

## Answer

### Exercise 3.4:
$Sol.$ Since the Rayleigh density is 
$$
f(x)= \frac{x}{\sigma^2} e^{−x^2/(2\sigma^2)},\quad x\ge0,σ>0. 
$$
we can obtain its cumulative density function by integral, which is 
$$
F_X (x) = 1- e^{−x^2/(2\sigma^2)},\quad x\ge0,σ>0.
$$
Then the inverse function will be
$$
F_X^{-1}(u) = \sigma\sqrt{-2\log (1-u)},\quad u\in (0,1)
$$
Now we can apply the inverse transform method by randomly generating $u\sim U(0,1)$ and transforming it into $F_X^{-1}(u)$, which follows a Rayleigh$(σ)$ distribution as we expect.In the following figures, the theoretical mode $σ$ is marked by blue vertical lines.

```{r}
set.seed(12345)
graph_hist = function(size, sigma){
  
  hist(x = sigma * sqrt(-2*log(runif(size))), prob = T,main="Sample from Rayleigh Distribution",xlab = "value") #histogram of the sample points 
  
  abline(v = sigma,lwd=4,col="blue") #the position of mode
}

graph_hist(10000,0.5)         # Histogram when sigma = 0.5

graph_hist(10000,1)        # Histogram when sigma = 1

graph_hist(10000,5)       # Histogram when sigma = 5



```




----

### Exercise 3.11
$Sol.$
```{r}
set.seed(54321)

ge_MN = function(n, p1){  # sample of mixture normal
    U = runif(n)
    Y = rep(0,n)
    for(i in 1:n){
      if(U[i] <= p1){
        Y[i] = rnorm(1)
      }
      else{
        Y[i] = rnorm(1) + 3
      }
    }
    
    hist(Y, probability = T, main = "Mixture Normal")
    count = 0
    for(i in 1:n){
      if(Y[i] <= 1.5){
        count = count + 1
      }
    }
    print("The conjecture about p1 is ")
    print(count/n)
}


ge_MN(5000, 0.25)
ge_MN(5000, 0.5)
ge_MN(5000, 0.75)

```


----

### Exercise 3.18:
$Sol.$ 
```{r}
library(matrixcalc)

ge_Wishart = function(n, Sigma){
  n = as.integer(n)
  d = nrow(Sigma)
  if(n <= d+1){
    return("error in dimension")
  }
  
  UL = chol(Sigma)                  
  # Choleski factorization, where UL is upper triangular
  
  MA = matrix(0, nrow = d, ncol = d)
  
  for(i in 1:d){
    MA[i,i] = sqrt(rchisq(1, n-i+1))
    if(i > 1){
      for(j in 1:(i-1)){
        MA[i,j] = rnorm(1)
      } 
    }
  }
  
  return(t(UL) %*% MA %*% t(MA) %*% UL)
}


```

```{r}
B = cbind(c(6,3,0),c(3,6,-6),c(0,-6,11))
ge_Wishart(5,B)
```

---

# HW2

## Question

Exercises 5.1, 5.10, 5.15 (pages 149-151, Statistical Computating with R).

---

## Answer

### Exercise 5.1
Compute a Monte Carlo estimate of 
$$
\int_{0}^{\pi/3} sint\ dt 
$$ 
and compare your estimate with the exact value of the integral. 

$sol.$We can apply the vanilla Monte Carlo here.First,we can sample $X_{1},...,X_{N}\ i.i.d\sim\ U(0,\pi/3)$.Then compute 
$$
\frac{\pi}{3}*\frac{1}{N}\sum_{i=1}^{N}X_{i}
$$
to obtain the estimate of the integral.
```{r}
N = 10000 ##size of Monte Carlo sample
est_Mon = pi/3*mean(runif(N,0,pi/3))
true_value = integrate(function(t){sin(t)},lower = 0,upper = pi/3)$value
print(paste("The Monte Carlo estimate is",round(est_Mon,3),"and the true value of the integral is",true_value))
```

---

### Exercise 5.10
Use Monte Carlo integration with antithetic variables to estimate 
$$
\int_{0}^{1}\frac{e^{-x}}{1+x^2}\ dx
$$
and ﬁnd the approximate reduction in variance as a percentage of the variance without variance reduction.

$sol.$First,we can sample $U_{1},...,U_{2N}\ i.i.d\sim\ U(0,1)$.Then, we can compute the Monte Carlo estimate:
$$
\frac{1}{2N}\sum_{i=1}^{2N}\frac{e^{-X_{i}}}{1+X_{i}^2}
$$
To compare the vanilla Monte Carlo and antithetic Monte Carlo, we denote the sum above by $F(X_1,...,X_2N)$ and compute $F(U_1,...U_2N)$ and $F(U_1,...U_N,1-U_{N+1},...1-U_{2N})$ respectively.
```{r}
f = function(x){
  return(exp(-x)/(1+x^2))
}  ##define the function f

U1 = runif(N,0,1)
U2 = runif(N,0,1)
est_van = mean(c(f(U1),f(U2)))
est_ant = mean(c(f(U1),f(1-U2)))
var_van = var(c(f(U1),f(U2)))
var_ant = var(c(f(U1),f(1-U2)))
reduction = (var_van - var_ant)/(var_van)
print(paste("The vanilla Monte Carlo estimate is",round(est_van,3)," the estimate with antithetic variables is",round(est_ant,3),"and the true value is",round(integrate(f,lower = 0,upper = 1)$value,3)))
print(paste("The variance of vanilla MC is",round(var_van,4),"and the variance of MC with antithetic variables is",round(var_ant,4),"reducing by",round(reduction,3)))

```

---

### Exercise 15 
Obtain the stratiﬁed importance sampling estimate in Example 5.13 and compare it with the result of Example 5.10.
$sol.$ For comparison,we use the two methods to obtain the estimates via the 3rd candidate for the importance functions. 
$$
f_3(x) = e^{-x}/(1-e^{-1}),\ 0<x<1
$$

```{r}
m <- 10000 #number of replicates
k <- 10 #number of strata
N0 <- 50 #number of times to repeat the estimation 
T = numeric(k)
estimates = matrix(0,N0,2)

g = function(t) { exp(-t - log(1+t^2)) * (t > 0) * (t < 1) }
fg = function(t) { g(t) / (exp(-t) / (1 - exp(-1))) }
inv = function(t) { - log(1 - t * (1 - exp(-1))) } ##inverse transform method 

for (i in 1:N0){
  estimates[i,1] = mean(fg(inv(runif(m))))
  for (j in 1:k){
    T[j] = mean(fg(inv(runif(m/k,(j-1)/k,j/k))))
  estimates[i,2] = mean(T) 
  }
}
v = apply(estimates, 2, var)

print(paste("The estimates of no-stratified and stratified are: ",round(apply(estimates, 2, mean),3)))
print(paste("The variances of no-stratified and stratified are: ",v))
print(paste("This represents a",100*round((v[1]-v[2])/v[1],2),"% reduction in variance."))



```

---

# HW3

## Question

Exercise 6.5,6.6 (page 180, textbook)

---

## Answer

### Exercise 6.5
Suppose a $95\%$ symmetric $t$-interval is applied to estimate a mean, but the sample data are non-normal. Then the probability that the confidence interval covers the mean is not necessarily equal to 0.95. Use a Monte Carlo experiment to estimate the coverage probability of the $t$-interval for random samples of $\chi^2(2)$ data with sample size $n = 20$. Compare your $t$-interval results with the simulation results in Example 6.4. (The $t$-interval should be more robust to departures from normality than the interval for variance.) 

$Sol.$  First, the $t$-interval to estimate a mean is $\left(\overline{x}-t_{\alpha/2}\frac{s}{\sqrt{n}},\overline{x}+t_{\alpha/2}\frac{s}{\sqrt{n}}\right)$. And the confidence interval for the variance in Example 6.4 is $(0,\frac{(n-1)s^2}{\chi_{0.05}^2 (n-1)})$. 
```{r}
set.seed(12345)

m = 5e4                    #MCMC sample size
n = 20                     #sample size

est1 = rep(0,m)            #MC estimate coverage probability of t-interval
est2 = rep(0,m)            #MC estimate coverage probability of chi2-interval

for(i in 1:m){
  
  X = rchisq(n, df = 2)    #sample from chi2 
  
  est1[i] = mean(X)- qt(0.975,n-1)*var(X)/sqrt(n) < 2 & mean(X) + qt(0.975,n-1)*var(X)/sqrt(n) > 2
  # the mean of the chi2 is 2
  
  est2[i] = (n-1)*var(X)/qchisq(0.05, df = n-1) > 4
  # the variance of the chi2 is 4
  
  }

mean(est1)             
mean(est2)           
```
As we can see, the coverage probability of $t$-interval is more close to 0.94, then it is more robust to departures from normality than the interval for variance.

---

### Exercise 6.6
Estimate the 0.025, 0.05, 0.95, and 0.975 quantiles of the skewness $\sqrt{b_1}$ under normality by a Monte Carlo experiment. Compute the standard error of the estimates from (2.14) using the normal approximation for the density (with exact variance formula). Compare the estimated quantiles with the quantiles of the large sample approximation $\sqrt{b_1} \approx N(0,6/n)$. 

$Sol.$ 
```{r}
set.seed(54321)
q0 = c(0.025,0.05,0.95,0.975)
n=500
m = 5e4
skew = rep(0,m)

for(i in 1:m){
  sam = rnorm(n)          
  skew[i] = mean((sam - mean(sam))^3)/(mean((sam - mean(sam))^2))^1.5           
  }
  
est1_q = quantile(skew, probs = q0)           
  
est2_q = qnorm(q0, sd = sqrt(6/n) )         

std1 = sqrt( q0*(1-q0)/n/( dnorm(est1_q, sd = sqrt(6/n)) )^2 )
# the standard error of sample quantile estimates 
  
result = cbind(est2_q, est1_q, std1)
colnames(result) = c("theoretical quantile(Normal)","sample quantile","standard error of sample quantile(2.14)")
  
knitr::kable(result)
```

---

# HW4

## Question

Exercises 6.7, 6.A, slides page 22 (pages 180-181, Statistical Computating with R).


## Answer

### Exercise 6.7
Estimate the power of the skewness test of normality against symmetric $\text{Beta} (\alpha,\alpha)$ distributions and comment on the results. Are the results different for heavy-tailed symmetric alternatives such as $\text{}t(\nu)$?

$Sol.$ 
```{r}
sk = function(x) { 
  #sample skewness 
  m1 = mean(x) 
  m3 = mean((x - m1)^3) 
  m2 = mean((x - m1)^2) 
  return( m3 / m2^1.5 ) 
} 

alpha = seq(0,3,0.5)
N = 5000  ##number of iterations
n = 30  ##sample size
sl = 0.05  ##significance level
result1 = rep(0,length(alpha))

for (j in 1:length(alpha)) {           
  cv = qnorm(1-sl/2, 0, sqrt(6*(n-2) / ((n+1)*(n+3))))  ##critical value for the skewness test
  skvector1 = rep(0,N)
  
  for (i in 1:N) {           
    x = rbeta(n, shape1 = alpha[j], shape2 = alpha[j]) 
    if (abs(sk(x)) >= cv) skvector1[i] = 1
    else skvector1[i] = 0
  } 
  
  result1[j] = mean(skvector1) 
}

plot(alpha, result1, type = "b",xlab = "a", ylab = "power",ylim = c(0,1),main = "Beta(a,a):significance level = 0.05") 
M = rbind(alpha, result1)
rownames(M) = c("alpha","power")
colnames(M) = 1:length(alpha)
knitr::kable(M)
```
```{r}
```
Comment: the power of the tests are very small, which means it is hard for us to reject the null hypothesis when the true skewness is far from normality.


```{r}
sk = function(x) { 
  #sample skewness 
  m1 = mean(x) 
  m3 = mean((x - m1)^3) 
  m2 = mean((x - m1)^2) 
  return( m3 / m2^1.5 ) 
} 

freedom = seq(1,10,1)
N = 5000  ##number of iterations
n = 30  ##sample size
sl = 0.05  ##significance level
result2 = rep(0,length(freedom))

for (j in 1:length(freedom)) {           
  cv = qnorm(1-sl/2, 0, sqrt(6*(n-2) / ((n+1)*(n+3))))  ##critical value for the skewness test
  skvector2 = rep(0,N)
  
  for (i in 1:N) {           
    x = rt(n, df = freedom[j])  
    if (abs(sk(x)) >= cv) skvector2[i] = 1
    else skvector2[i] = 0
  } 
  
  result2[j] = mean(skvector2) 
}

plot(freedom, result2, type = "b",xlab = "fr", ylab = "power",ylim = c(0,1),main = "t(fr): significance level = 0.05") 
M = rbind(freedom, result2)
rownames(M) = c("degree of fr","power")
colnames(M) = 1:length(freedom)
knitr::kable(M)
```
```{r}
```
Comments: the power of the tests is big when $degree\ of\ freedom(\nu)$ is small and when $degree\ of\ freedom(\nu)$ becomes larger, $\text{}t(\nu)$ becomes close to the standard gaussian, with the power tending to be small.


### Exercise 6.A
Use Monte Carlo simulation to investigate whether the empirical Type I error rate of the $t$-test is approximately equal to the nominal significance level $\alpha$, when the sampled population is non-normal. The $t$-test is robust to mild departures from normality. Discuss the simulation results for the cases where the sampled population is:
(i) $\chi^2 (1)$, (ii) Uniform$(0,2)$, and (iii) Exponential(rate$=1$). In each case, test $H_0 : \mu = \mu_0$ vs $H_1 : \mu\neq \mu_0$, whereµ0 is the mean of $\chi^2 (1)$, Uniform$(0,2)$, and Exponential($1$), respectively.

$Sol.$
Case 1: $\chi^2 (1)$
```{r}
sl = c(0.01,0.05,0.1,0.2)
N = 3000 ##number of iterations
n = 30 ##sample size
result3 = rep(0,length(sl))

for(j in 1:length(sl)){
    
    t1e_vector = rep(0,n) 

    for(i in 1:N){
      x = rchisq(n, df = 1)                                              
      q = qt(1-sl[j]/2, df = n-1)                                      
      t1e_vector[i] = mean(abs(mean(x)-1)>q*var(x)/sqrt(n))  ## the mean of chi^2(1) is 1
    }
    
    result3[j] = mean(t1e_vector)
  }

result3 = round(result3,3)
M = rbind(sl, result3)
rownames(M) = c("significance level","empirical type I error rate")
colnames(M) = 1:length(sl)
knitr::kable(M)
```
```{r}
```
Comments: type I error rate is rather different from the significance level.

Case 2: Uniform$(0,2)$
```{r}
sl = c(0.01,0.05,0.1,0.2)
N = 3000 ##number of iterations
n = 30 ##sample size
result4 = rep(0,length(sl))

for(j in 1:length(sl)){
    
    t1e_vector = rep(0,n) 

    for(i in 1:N){
      x = runif(n, min = 0, max = 2)                                               
      q = qt(1-sl[j]/2, df = n-1)                                      
      t1e_vector[i] = mean(abs(mean(x)-1)>q*var(x)/sqrt(n))  ## the mean of chi^2(1) is 1
    }
    
    result4[j] = mean(t1e_vector)
  }

result4 = round(result4,3)
M = rbind(sl, result4)
rownames(M) = c("significance level","empirical type I error rate")
colnames(M) = 1:length(sl)
knitr::kable(M)
```
```{r}
```
Comments: type I error rate is rather different from the significance level.


Case 3: Exponential($1$)
```{r}
sl = c(0.01,0.05,0.1,0.2)
N = 3000 ##number of iterations
n = 30 ##sample size
result5 = rep(0,length(sl))

for(j in 1:length(sl)){
    
    t1e_vector = rep(0,n) 

    for(i in 1:N){
      x = rexp(n, rate = 1)                                               
      q = qt(1-sl[j]/2, df = n-1)                                      
      t1e_vector[i] = mean(abs(mean(x)-1)>q*var(x)/sqrt(n))  ## the mean of chi^2(1) is 1
    }
    
    result5[j] = mean(t1e_vector)
  }

result5 = round(result5,3)
M = rbind(sl, result5)
rownames(M) = c("significance level","empirical type I error rate")
colnames(M) = 1:length(sl)
knitr::kable(M)

```
```{r}
```
Comments: type I error rate is rather different from the significance level.

### Discussion slides page 22
If we obtain the powers for two methods under a particular simulation setting with 10,000 experiments: say, 0.651 for one method and 0.676 for another method. Can we say the powers are different at 0.05 level?

#### Q1. What is the corresponding hypothesis test problem?
Null hypothesis： the powers (for two methods under a particular simulation setting) are same.
Alternative hypothesis： the powers are different.
Test the hypothesis at the significance level = 0.05.

#### Q2. What test should we use? 
Two-sample t-test. Since the power is the expectation of the method result, it is equivalent to say that we need to test the difference between two population means.

#### Q3. What information is needed to test your hypothesis?
The mean and standard deviation of both sample.

---

# HW5

## Question

Exercise 7.6 and Project 7.B(Statistical Computing with R, pages 212-213).

---

## Answer

### Exercise 7.6
Efron and Tibshirani discuss the $scor\ (bootstrap)$ test score data on 88 students who took examinations in ﬁvesubjects [84, Table 7.1], [188, Table 1.2.1]. The first two tests (mechanics, vectors) were closed book and the last three tests (algebra, analysis, statistics) were open book. Each row of the data frame is a set of scores $(x_{i1},\dots,x_{i5})$ for the $i$th student. Use a panel display to display the scatter plots for each pair of test scores. Compare the plot with the sample correlation matrix. Obtain bootstrap estimates of the standard errors for each of the following estimates: $\hat{\rho}_{12}=\hat{\rho}(\text{mec, vec})$, $\hat{\rho}_{34}=\hat{\rho}(\text{alg, ana})$, $\hat{\rho}_{35}=\hat{\rho}(\text{alg, sta})$, $\hat{\rho}_{45}=\hat{\rho}(\text{ana, sta})$.


$Sol.$
```{r}
#PART1: plot
library(bootstrap)
par(mfrow = c(2, 5))
```

The sample correlation matrix is:
```{r}
#PART2: sample correlation matrix
print(cor(scor))
```

```{r}
#PART3: boostrap estimate
library(boot)
coreff <- function(x,i) cor(x[i,1],x[i,2])
M = matrix(0,4,1)

#standard errors of cor(mec,vec)
M[1,1] = sd(boot(data = scor[,c(1,2)], statistic = coreff, R=1000)$t)

#standard errors of cor(alg,ana)            
M[2,1] = sd(boot(data = scor[,c(3,4)], statistic = coreff, R=1000)$t)


#standard errors of cor(alg,sta)
M[3,1] = sd(boot(data = scor[,c(3,5)], statistic = coreff, R=1000)$t)


#standard errors of cor(ana,sta)
M[4,1] = sd(boot(data = scor[,c(4,5)], statistic = coreff, R=1000)$t)

colnames(M) = c("boot est of standard errors")
rownames(M) = c("cor(mec,vec)","cor(alg,ana)","cor(alg,sta)","cor(ana,sta)")
knitr::kable(M)
```

---

### Project 7.B
Repeat Project 7.A for the sample skewness statistic. Compare the coverage rates for normal populations (skewness $0$) and $\chi^2(5)$ distributions (positive skewness).


$Sol.$
```{r}
b.sk <- function(x,i){
  m1 = mean(x[i,])
  m3 = mean((x[i,] - m1)^3) 
  m2 = mean((x[i,] - m1)^2) 
  return(m3 / m2^1.5) 
}


#PART1: Normal
N = 1000 ##number of iterations
n = 30   ##sample size
R = 1000 ##bootstrap number
cp.norm = rep(0,N)
cp.basic = rep(0,N)
cp.perc = rep(0,N)
count.norml = 0
count.normr = 0
count.basicl = 0
count.basicr = 0
count.percl = 0
count.percr = 0


for(i in 1:N){
  data_x = as.matrix(rnorm(n))
  obj = boot.ci(boot(data = data_x, statistic = b.sk, R = R), conf = 0.95, 
                type = c("norm", "basic", "perc"))
    
  cp.norm[i] = obj$norm[2] <= 0 & obj$norm[3] >= 0
  if (obj$norm[2] > 0) count.norml = count.norml+1
  if (obj$norm[3] < 0) count.normr = count.normr+1
  cp.basic[i] = obj$basic[4] <= 0 & obj$basic[5] >= 0
  if (obj$basic[4] > 0) count.basicl = count.basicl+1
  if (obj$basic[5] < 0) count.basicr = count.basicr+1
  cp.perc[i] = obj$perc[4] <= 0 & obj$perc[5] >= 0
  if (obj$perc[4] > 0) count.percl = count.percl+1
  if (obj$perc[5] < 0) count.percr = count.percr+1
  # the skewness of a normal distribution is 0 
  }
  
result1 = rbind(c(mean(cp.norm),mean(cp.basic),mean(cp.perc)),c(count.norml/N,count.basicl/N,count.percl/N),c(count.normr/N,count.basicr/N,count.percr/N))

#PART2: Chi^2(5)
N = 1000 ##number of iterations
n = 30   ##sample size
R = 1000 ##bootstrap number
cp.norm = rep(0,N)
cp.basic = rep(0,N)
cp.perc = rep(0,N)
count.norml = 0
count.normr = 0
count.basicl = 0
count.basicr = 0
count.percl = 0
count.percr = 0

for(i in 1:N){
  data_x = as.matrix(rchisq(n, df = 5))
  obj = boot.ci(boot(data = data_x, statistic = b.sk, R = R), conf = 0.95, 
                type = c("norm", "basic", "perc"))
    
  cp.norm[i] = obj$norm[2] <= 2*sqrt(0.4) & obj$norm[3] >= 2*sqrt(0.4)
  if (obj$norm[2] > 2*sqrt(0.4)) count.norml = count.norml+1
  if (obj$norm[3] < 2*sqrt(0.4)) count.normr = count.normr+1
  cp.basic[i] = obj$basic[4] <= 2*sqrt(0.4) & obj$basic[5] >= 2*sqrt(0.4)
  if (obj$basic[4] > 2*sqrt(0.4)) count.basicl = count.basicl+1
  if (obj$basic[5] < 2*sqrt(0.4)) count.basicr = count.basicr+1
  cp.perc[i] = obj$perc[4] <= 2*sqrt(0.4) & obj$perc[5] >= 2*sqrt(0.4)
  if (obj$perc[4] > 2*sqrt(0.4)) count.percl = count.percl+1
  if (obj$perc[5] < 2*sqrt(0.4)) count.percr = count.percr+1
  # the skewness of chi^2(fd) distribution is 2*sqrt(2/fd)
  }
  
result2 = rbind(c(mean(cp.norm),mean(cp.basic),mean(cp.perc)),c(count.norml/N,count.basicl/N,count.percl/N),c(count.normr/N,count.basicr/N,count.percr/N))
```

```{r}
M2 = rbind(result1,result2)
rownames(M2) = c("normal","proportion of miss left","proportion of miss right","chi^2(5)","proportion of miss left","proportion of miss right")
colnames(M2) = c("normal","basic","precentile")
knitr::kable(M2)
```

---

# HW6

## Question

Exercises 7.8 and 7.10 (Statistical Computing with R, page 213)

---

## Answer

### Exercise 7.6
Refer to Exercise 7.7. Obtain the jackknife estimates of bias and standard error of $\hat\theta$. 
$Sol.$
```{r}
pr1 = function (M){ ##the proportion of variance explained by the ﬁrst principal component
  lambda = eigen(M)$values
  if (min(lambda)<=0) return(NULL)
  return(max(lambda)/sum(lambda))
}

jack_pr = function (data){
  n = ncol(data)
  theta.jack = rep(0,n)
  for (i in n){
    theta.jack[i] = pr1(M = cov(data[,-i]))
  }
  theta.hat = pr1(M = cov(data))
  return(c((n-1)*(mean(theta.jack)-theta.hat),sqrt((n-1)*mean((theta.jack - mean(theta.jack))^2))))
}

library(bootstrap)
result = jack_pr(scor)
M = matrix(data = result,1,2)
colnames(M) = c("est of bias","est of std")
rownames(M) = c("value")
knitr::kable(M)

```

---

### Project 7.10
In Example 7.18, leave-one-out (n-fold) cross validation was used to select the best fitting model. Repeat the analysis replacing the Log-Log model with a cubic polynomial model. Which of the four models is selected by the cross validation procedure? Which model is selected according to maximum adjusted $R^2$? 

$Sol.$
```{r}
library(DAAG)
attach(ironslag) 

# for n-fold cross validation 
# fit models on leave-one-out samples 

jack_coef_cv = function(data = NULL){
  n = length(magnetic)
  e1 <- e2 <- e3 <- e4 <- rep(n,0)

for (i in 1:n) {
  y = magnetic[-i] 
  x = chemical[-i]
  
  J1 <- lm(y ~ x) 
  yhat1 <- J1$coef[1] + J1$coef[2] * chemical[i] 
  e1[i] <- magnetic[i] - yhat1
  
  J2 <- lm(y ~ x + I(x^2)) 
  yhat2 <- J2$coef[1] + J2$coef[2] * chemical[i] + J2$coef[3] * chemical[i]^2   
  e2[i] <- magnetic[i] - yhat2
  
  J3 <- lm(log(y) ~ x) 
  logyhat3 <- J3$coef[1] + J3$coef[2] * chemical[i] 
  yhat3 <- exp(logyhat3)
  e3[i] <- magnetic[i] - yhat3
  
  J4 <- lm(y ~ poly(x,3,raw=T)) 
  yhat4 <- J4$coef[1] + J4$coef[2] * chemical[i] + J4$coef[3] * chemical[i]^2 + J4$coef[4] * chemical[i]^3
  e4[i] <- magnetic[i] - yhat4
}
  return(c(mean(e1^2),mean(e2^2),mean(e3^2),mean(e4^2)))
}

result = jack_coef_cv()
M = matrix(data = result,1,4)
colnames(M) = c("linear","quadratic","log","cubic")
rownames(M) = c("prediction error")
knitr::kable(M)
```
```{r}
```
According to the prediction error criterion, Model 2, the quadratic model, would be the best fit for the data.
```{r}
y = magnetic
x = chemical
summary(lm(y ~ x + I(x^2)) )
```

```{r}
R2_coef = function(data = NULL){
  e1 <- e2 <- e3 <- e4 <- 0

  y = magnetic
  x = chemical
  
  e1 <- summary(lm(y ~ x))$adj.r.squared
  e2 <- summary(lm(y ~ x + I(x^2)))$adj.r.squared
  e3 <- summary(lm(log(y) ~ x))$adj.r.squared
  e4 <- summary(lm(y ~ poly(x,3,raw=T)))$adj.r.squared

  return(c(e1,e2,e3,e4))
}

result = R2_coef()
M = matrix(data = result,1,4)
colnames(M) = c("linear","quadratic","log","cubic")
rownames(M) = c("Adjusted R Square")
knitr::kable(M)
```
```{r}
```
According to the adjusted R square criterion, Model 3, the log model, would be the best fit for the data.
```{r}
y = magnetic
x = chemical
summary(lm(log(y) ~ x))
```

---

# HW8

## Question

Exercise 8.3 (Statistical Computing with R, page 243) and slides page 31.

---

## Answer

### Exercise 8.3
The Count 5 test for equal variances in Section 6.4 is based on the maximum number of extreme points. Example 6.15 shows that the Count 5 criterion is not applicable for unequal sample sizes. Implement a permutation test for equal variance based on the maximum number of extreme points that applies when sample sizes are not necessarily equal.

$Sol.$
Assume the sample size of $X$ is $m$ and size of $Y$ is $n$, and without loss of generality, assume $m<n$. Conisder $Z = c\left(X,Y\right)$ and the statistics:

$$
\hat{\theta} := maxout\{Z[1:m],Z[(m+1):2m]\}
$$
and then do permutation test.(See Page 177 on Statistical Computing with R for details of $maxout$)
```{r}
maxout = function(x,y){
  X = x - mean(x) 
  Y = y - mean(y) 
  outx = sum(X > max(Y)) + sum(X < min(Y)) 
  outy = sum(Y > max(X)) + sum(Y < min(X)) 
  return(max(c(outx, outy)))
}
count5_permutation = function(X,Y,N){
  if(length(X)<=length(Y)){
    m = length(X)
    Z = c(X,Y)
    theta.hat = maxout(X,Y)
  }
  else {
    m = length(Y)
    Z = c(Y,X)
    theta.hat = maxout(Y,X)
  }
  theta.per = rep(0,N)
  for (i in 1:N){
    ind = sample(1:length(Z),size = 2*m, replace = F)
    z0 = Z[ind]
    theta.per[i] = maxout(z0[1:m],z0[(m+1):(2*m)])
  }
  out = (1+sum(theta.per>=theta.hat))/(1+N)  ##p-value of count-five test
}
```
```{r}
##exmaple 6.15

m = 500
n = 600
N0 = 300
result = rep(0,N0)
for(i in 1:N0){
  result[i] = count5_permutation(rnorm(m),rnorm(n),1e3)
}

```
The p-value of testing same variances is: 
```{r}
mean(result) ##p-value
```

```{r}
##exmaple 6.15

m = 500
n = 600
N0 = 300
result = rep(0,N0)
for(i in 1:N0){
  result[i] = count5_permutation(rnorm(m),1.5*rnorm(n),1e3)
}

```
The p-value of testing different variances is: 
```{r}
mean(result) ##p-value
```

----

### slides page 31

Power comparison (distance correlation test versus ball covariance test)
$$
     Model\ 1: Y=X/4+\epsilon\\
     Model\ 2: Y=X/4\times \epsilon\\
     X\sim N(0_2,I_2),\ \epsilon\sim N(0_2,I_2),\\
     X\ and\ \epsilon\ are\ independent.
$$
$Sol.$ 

```{r}
library(Ball)
library(energy)

power_comparison = function(n, N, alpha = 0.1){
  ## n is the sample size
  ## N is the number of replication
  p.dist = matrix(0,N,2)
  p.ball = matrix(0,N,2)
  
  for(i in 1:N){
    X = matrix(rnorm(2*n), nrow = n, ncol = 2)
    e = matrix(rnorm(2*n), nrow = n, ncol = 2)
    Y1 = X/4 + e
    Y2 = X/4 * e
    p.ball[i,1] = bd.test(x = X, y = Y1, seed = i*54321, R = 99)$p.value
    p.dist[i,1] = dcor.test(x = X, y = Y1, R = 99)$p.value
    p.ball[i,2] = bd.test(x = X, y = Y2, seed = i*12345, R = 999)$p.value
    p.dist[i,2] = dcor.test(x = X, y = Y2, R = 99)$p.value
  }
  return(c(mean(p.ball[,1] < alpha), mean(p.dist[,1] < alpha), mean(p.ball[,2] < alpha), mean(p.dist[,2] < alpha)))
}


vec.n = seq(10, 60, 10)
matrix.power = matrix(0, nrow = 5, ncol = length(vec.n))
for(i in 1:length(vec.n)){
  matrix.power[,i] = c(vec.n[i],power_comparison(vec.n[i], 2e2))
}
# rownames(matrix.power) = c( "sample size","dcor test1", "ball test1","dcor test2", "ball test2" )
# knitr::kable(matrix.power)

plot(vec.n, matrix.power[2,], type="l", col = "red", lty=3, ylim = c(0,1),xlab = "sample size", ylab = "power", main = "model1")
lines(vec.n, matrix.power[3,], type = "l", col = "blue", lty =3)
legend("bottomright", c("ball","dcor"), fill = c("red","blue"))

plot(vec.n, matrix.power[4,], type="l", col = "red", lty=3, ylim = c(0,1),xlab = "sample size", ylab = "power", main = "model2")
lines(vec.n, matrix.power[5,], type = "l", col = "blue", lty =3)
legend("bottomright", c("ball","dcor"), fill = c("red","blue"))
```

---

# HW11

## Question

Exercises 11.1 and 11.5 (Statistical Computing with R, pages 353-354) and Assignment-12-06.

## Answer

### Exercise 11.1
The natural logarithm and exponential functions are inverses of each other, so that mathematically $\log(\exp x) = \exp(\log x)=x$. Show by example that this property does not hold exactly in computer arithmetic. Does the identity hold with near equality? (See $all.equal.$) 

$Sol.$ We use the function $identical$ to test the exact equality and $all.equal$ to test the near equality.
```{r}
v = c(0.1,1,10,100)
M = matrix(0,2,length(v))
for (i in 1:length(v)){
  M[1,i] = identical(log(exp(v[i])),exp(log(v[i])))
  M[2,i] = isTRUE(all.equal(log(exp(v[i])),exp(log(v[i]))))
}
```
```{r echo=FALSE}
colnames(M) = v
rownames(M) = c("identical","all.equal")
knitr::kable(M)
```

Here, "1" means True and "0" means False.

---

### Exercise 11.5
Write a function to solve the equation:
$$
\begin{aligned} \frac{2 \Gamma\left(\frac{k}{2}\right)}{\sqrt{\pi(k-1)} \Gamma\left(\frac{k-1}{2}\right)} \int_{0}^{c_{k-1}}\left(1+\frac{u^{2}}{k-1}\right)^{-k / 2} d u = \frac{2 \Gamma\left(\frac{k+1}{2}\right)}{\sqrt{\pi k} \Gamma\left(\frac{k}{2}\right)} \int_{0}^{c_{k}}\left(1+\frac{u^{2}}{k}\right)^{-(k+1) / 2} d u \end{aligned}
$$
for $a$, where
$$
c_{k}=\sqrt{\frac{a^{2} k}{k+1-a^{2}}}
$$
Compare the solutions with the points $A(k)$ in Exercise 11.4.

$Sol.$

#### Ex11.4

```{r}
func_S = function(a,k){
  b = 1-pt(q = sqrt((a^2)*k/(k+1-a^2)),df = k)
  return(b)
}
vec_k = c(5:10,50:55)
result2 = rep(0,length(vec_k))
for(i in 1:length(vec_k)){
  result2[i] = uniroot(function(y){func_S(a=y,k=vec_k[i])-func_S(a=y,k=vec_k[i]-1)},interval = c(1,min(2,sqrt(vec_k[i]))))$root
}
```

#### Ex11.5

```{r}
func_intel = function(a,k){
  f = function(u) (1+u^2/k)^(-(k+1)/2)
  b = exp(lgamma((k+1)/2)-lgamma(k/2))/sqrt(k)*integrate(f,lower = 0,upper = sqrt((a^2)*k/(k+1-a^2)))$value
  return(b)
}

vec_k = c(5:10,50:55)
result = rep(0,length(vec_k))
for(i in 1:length(vec_k) ){
  result[i] = uniroot(function(y) {func_intel(a = y,k = vec_k[i])-func_intel(a = y,k = vec_k[i]-1)},interval = c(1,min(2,sqrt(vec_k[i])-1e-4)))$root
}
```
```{r echo=FALSE}
M2 = matrix(0,2,length(vec_k))
M2[1,] = result
M2[2,] = result2
colnames(M2) = vec_k
rownames(M2) = c("Ex5","Ex4")
knitr::kable(M2)
```

---

### Assignment
A-B-O blood type problem 

$Sol.$ 
```{r}
E_step = function(para,p0,q0,nA=28,nB=24,nO=41,nAB=70){
  p = para[1]
  q = para[2]
  b = 2*nA*log(p)+2*nB*log(q)+2*nO*log(1-p-q)+nAB*log(p)+nAB*log(q)+nA*2*(1-p0-q0)/(2-2*q0-p0)*log(2*(1-p-q)/p)+nB*2*(1-p0-q0)/(2-2*p0-q0)*log(2*(1-p-q)/q)
  return(b)
}

##M_step
N = 10
p0 = 0.2
q0 = 0.2
p_rec = rep(0,N)
q_rec = rep(0,N)
loglike = rep(0,N)

for(i in 1:N){
  obj = function(y) -E_step(para = y, p0,q0)
  itr = optim(par = c(0.3,0.3),fn = obj)
  p0 = itr$par[1]
  q0 = itr$par[2]
  p_rec[i] = itr$par[1]
  q_rec[i] = itr$par[2]
  loglike[i] = itr$value
}
```

```{r echo=FALSE}
plot(1:N,loglike,col = "red",type = "l",xlab = "iteration",ylab = "log-likelihood")

plot(p_rec,col = "blue",type = "l",ylim = c(0.28,0.35),xlab = "iteration",ylab = "p&q")
lines(q_rec,col = "purple",type = "l")
legend("topright",c("p","q"),lty = c(1,1),col = c("blue","purple"))
M3 = matrix(0,1,2)
M3[1,] = round(c(p_rec[N],q_rec[N]),3)
colnames(M3) = c("p","q")
rownames(M3) = c("MLE")
knitr::kable(M3)

```

---

# HW12

## Question
Exercises 3, 4, 5 (page 204, Advanced R), Excecises 3 and 7 (page 214, Advanced R)

---

## Answer
### Exercise 3
Use both for loops and $lapply()$ to fit linear models to the mtcars using the formulas stored in this list:
```{r}
formulas <- list( 
  mpg ~ disp, 
  mpg ~ I(1 / disp), 
  mpg ~ disp + wt, 
  mpg ~ I(1 / disp) + wt ) 
```
$Sol.$
```{r}
## for loop
for(i in 1:length(formulas)){
  result = lm(formulas[[i]], data = mtcars)
  print(result)
}
```
```{r}
## lapply
lapply(formulas, function(f) lm(f, data = mtcars))
```

---

### Exercise 4
Fit the model $mpg ~ disp$ to each of the bootstrap replicates of mtcars in the list below by using a for loop and $lapply()$. Can you do it without an anonymous function?
```{r}
bootstraps <- lapply(1:10, function(i) {
  rows <- sample(1:nrow(mtcars), rep = TRUE) 
  mtcars[rows, ] }
  ) 
```
$Sol.$
```{r}
## for loop 
for(i in 1:length(bootstraps)){
  print(lm(mpg~disp,data = bootstraps[[i]]))
}
```

```{r}
## lapply
lapply(bootstraps, function(data) lm(mpg ~ disp,data = data))
```

---

### Exercise 5
For each model in the previous two exercises, extract $R^2$ using the function below.
```{r}
rsq <- function(mod) summary(mod)$r.squared
```
$Sol.$
```{r}
lapply(formulas, function(f) rsq(lm(f,data = mtcars)))
```

---

### Excecises 3
The following code simulates the performance of a t-test for non-normal data. Use $sapply()$ and an anonymous function to extract the p-value from every trial.
```{r}
trials <- replicate( 
  100, 
  t.test(rpois(10, 10), rpois(7, 10)), 
  simplify = FALSE ) 
```
$Sol.$
```{r}
sapply(trials, function(item) item$p.value)
```



